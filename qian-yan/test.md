---
description: VERY DEEP CONVOLUTIONAL NETWORKS FOR LARGE-SCALE IMAGE RECOGNITION论文阅读记录
---

# No.1 VGG

VGG提出在整个网络结构中都使用简单的3\*3卷积核，以及maxpooling来组成基本的网络结构单元。通过叠加单元，在网络结构不变的情况下加深网络的深度，来达到当时的顶尖水平。

#### 论文中提出的结构示意图如下：

![](../.gitbook/assets/bu-huo.PNG)

论文从提出采用3\*3卷积开始，通过与现有的7\*7，5\*5对比，发现虽然3\*3卷积核感受范围较小，但是通过级联若干层也可以达到与较大卷积核相同的事业范围。而且通过级联也带来了优势，多层的级联有助于非线性函数的性能增强（相当于将之前的单独激活函数变成了若干的激活函数级联，所以可以提升性能）具体如下：

#### 引入cs231n上面一段话：几个小滤波器卷积层的组合比一个大滤波器卷积层好：

假设你一层一层地重叠了3个3x3的卷积层（层与层之间有非线性激活函数）。在这个排列下，第一个卷积层中的每个神经元都对输入数据体有一个3x3的视野。第二个卷积层上的神经元对第一个卷积层有一个3x3的视野，也就是对输入数据体有5x5的视野。同样，在第三个卷积层上的神经元对第二个卷积层有3x3的视野，也就是对输入数据体有7x7的视野。假设不采用这3个3x3的卷积层，二是使用一个单独的有7x7的感受野的卷积层，那么所有神经元的感受野也是7x7，但是就有一些缺点。

首先，多个卷积层与非线性的激活层交替的结构，比单一卷积层的结构更能提取出深层的更好的特征。其次，假设所有的数据有C个通道，那么单独的7x7卷积层将会包含7\*7\*C=49C2个参数，而3个3x3的卷积层的组合仅有个3\*（3\*3\*C）=27C2个参数。直观说来，最好选择带有小滤波器的卷积层组合，而不是用一个带有大的滤波器的卷积层。前者可以表达出输入数据中更多个强力特征，使用的参数也更少。唯一的不足是，在进行反向传播时，中间的卷积层可能会导致占用更多的内存。

同时作者还提出了采用1\*1的卷积核，来单纯的提升非线性性能。在后续的模型测评中有队这种方法做比较。

### 在训练的过程中作者分步提出了改进的方法以及对比

首先是**深层网络的初始化**问题，深层的网络如果初始化不合适的话。在后续的训练中就会有梯度无法较好的下降的问题。所以作者提出了先构建一个浅层的网络训练（浅到可以直接采用随机初始化也可以训练到比较理想的结果。），再将浅层网络的训练结果载入深层网络对应的层作为初始化的方案。

还有对于输入的图片scale的选择问题，是否将所有的图片统一到统一scale。作者将两种方案都进行的训练并进行了对比。

